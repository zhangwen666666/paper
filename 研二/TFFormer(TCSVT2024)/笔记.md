# 摘要

* 存在的问题
  * 大多数现代的时序动作定位方法主要集中在时间领域的信息上，而忽略了其他领域信息的优势
  * 如何以一种合理的方式有效地利用来自于不同领域的信息以及他们的相互作用，仍然是TAL中的一个问题。
* 在本文中，提出了一种新颖的跨时频（cross time-frequency）Transformer模型（TFFormer）用于时序动作定位（TAL）。
  * 设计了一种双分支网络结构，以捕捉多尺度下的时间和频率特征，在时间分支采用多尺度transformer，频率分支采用DB1离散小波变换（DWT）。
  * 为了融合这些来自不同领域的特征，提出了一个跨时频注意机制，包括一个时间路径和一个频率路径，加强时间和频率特征之间的相互作用。
  * 此外，设计了一种门控控制机制来聚合来自不同尺度的特征，表征不同尺度特征的各自贡献。
  * 设计了一个新的回归损失函数定位的时间边界。
* 在四个具有挑战性的基准数据集上进行了广泛的实验，包括两个第三人称数据集和两个第一人称数据集。
  * 在Ego 4D上实现了23.2%的平均mAP，在EPIC-Kitchen 100上实现了25.6%的平均mAP，大大超过了之前的最先进水平。
  * 它还在ActivityNet v1.3和THUMOS 14上获得了具有竞争力的结果，平均mAP为36.2%和67.8%。
  * 我们还进行了广泛的消融研究，以验证所提出的方法中每个组件的有效性。





# 介绍

## 1.时序动作定位所面临的问题

* 由于视频中每个动作实例的持续时间不同，因此需要处理不同长度的动作实例。以前的一些研究使用多尺度处理方法来解决这个问题。在多尺度处理中需要考虑**两个关键问题：**
  * 应该从什么域提取多尺度特征，
  * 不同尺度的信息如何相互作用。
* 缺乏有效的方法来解决这两个问题，极大地阻碍了现有的多尺度加工研究的性能。**因此，探索更有效的多尺度处理方法是TAL必须解决的问题。**

## 2.针对上述的问题所提出的解决方法

### 对于域选择的问题：

* 现有TAL方法在时域中执行多尺度操作，即以各种时间分辨率提取时间特征。

* 虽然多尺度时间特征擅长捕捉动作的时间变化和局部运动特征，但它们**本质上缺乏传达关于动作频率的信息的能力**。

* **包含频域信息可以通过提供对动作的周期性性质的有价值的见解**来弥合这一差距。(例如，频域信息可以有效地区分慢动作和快动作的节奏，并且可以精确地确定舞蹈或体育等活动中的特定节奏模式）。频域知识的融合补充了动作的时间动态特征与周期属性，丰富了我们对动作的理解。

* 此外，在提到多尺度或多分辨率操作时，自然会联想到**小波分解**的概念，因为它是多尺度理论中的基石。小波分解主要在频域内进行信号分析。

* 这启发我们设计能够在时域和频域上同时综合多尺度特征的方法，如图1所示。

  ![image-20241028101649493](C:\Users\PC\AppData\Roaming\Typora\typora-user-images\image-20241028101649493.png)

### 对于不同尺度之间的信息交互问题：

* 现有的一些方法忽略了尺度之间的相互作用，直接对每个尺度的特征进行后处理，这可能会限制多尺度处理的潜力。
* 另一方面，以前的一些方法通过上/下采样直接组合尺度之间的特征，这可能引入不相关的信息。
* 这些问题促使我们设计一种**门控控制机制，该机制动态地调整每个尺度特征的贡献，同时在不同尺度之间进行特征交互**，如图1（B）所示。

### TFFormer网络架构

* 提出了一种新的网络架构，称为TFFormer，聚合频域和时域特征，从输入视频中提取特征金字塔，并将不同尺度的特征与建议的门控控制机制相结合。
* 它由四个主要部分组成：
  * 多尺度时频特征编码器(multi-scale time-frequency feature encoder)：对于时间分支，我们利用Transformer中的**自注意力来为每个尺度建模时间上下文**；对于频率分支，我们通过**引入离散小波变换（DWT）来构造特征金字塔来提取频率特征**。
  * 交叉时频注意(cross time-frequency attention)：通过交叉注意融合多尺度时频特征。
  * 门控多尺度特征融合(gated multi-scale feature fusion)：采用门控控制机制动态调整每个尺度特征的贡献。
  * 轻量级特征解码器(lightweight feature decoder)：对于每个动作候选，解码器用于对动作进行分类并定位时间边界。

### 本文的贡献

* 据我们所知，这是**首次尝试探索多尺度时域和频域特征的交叉融合**，以丰富在单阶段TAL框架内的动作特征表示。
* 我们**设计了一个新的网络TFFormer**。它利用双分支多尺度编码器提取时间和频率特征，并引入跨时频注意力来聚合时间和频率信息。提出了一种门控机制来过滤和整合来自不同尺度的特征。
* 我们在四个视频基准数据集上进行了广泛的实验，并取得了令人印象深刻的性能。





# 相关工作

## 时序动作定位

* Temporal Action Localization

* 一些现有的时间序列分析（TAL）方法侧重于多阶段流程。具体来说，这些方法首先生成一些视频片段作为动作候选，然后对每个有效的动作候选进行动作分类和时间边界的细化。这些方法高度依赖于候选动作的质量。
* 一些其他方法遵循单阶段流水线，其目标是在单个镜头中对来自未修剪视频的动作实例进行分类和定位。TriDet [13]通过边界的估计相对概率分布预测动作边界。然而，它需要先验条件，因此TriDet通过设置不同大小的bin来满足这一要求。与TriDet不同的是，**本文的方法直接基于单个时刻进行边界偏移量的回归。**
* 受上述研究的启发，**我们提出了一个基于Transformer的单阶段无锚模型。**

## 视觉中的小波变换

* Wavelet Transform in Vision  
* 小波变换在时频分析中已被证明是有效的，并已被利用在几个网络架构，以提高各种视觉任务的性能。
* 一些研究利用通过小波变换获得的高/低频或高/低分辨率信息。
* 另外，近年来也有一些研究探索了Transformer与小波变换的结合。
* 基于上述研究，**本文利用小波变换获取多尺度频率信息，并利用交叉注意机制将其与多尺度时间信息进行交互。**

## Transformer模型

* DETR将对象检测转换为集合预测问题。
* ViT [51]展示了Transformer如何在大规模图像数据集上取代深度神经网络中的标准卷积。
* 我们的TAL架构也基于Transformer。





# 方法

## 回顾

### 公式化问题

* 假设输入视频$V$由$T$个非重叠片段组成，每个片段由连续帧组成。每个片段的特征可以通过现有的动作识别网络提取。因此输入视频$V$可以表示为对应于$T$个片段的特征向量的集合：$V=\{v_{1}, v_{2}, ..., v_{T}\}$，其中$v_{t}$表示特征向量的第$t$个片段。

* TAL的预期输出被定义为预测动作实例的集合：$O=\{o_{1},o_{2},...,o_{N}\}$。$N$是视频中预测的动作实例的数量。每个动作实例$o_{i}$可以被表示为$o_{i}=(s_{i},e_{i},c_{i})$，其中$s_{i}\in[1,T]$和$e_{i}\in[1,T]$ ($s_{i}<e_{i}$)分别表示动作的开始和结束时间。$c_{i}\in\{1,2,...,C\}$表示动作类别，$C$表示预定义动作类别的数量。

* 将每个时刻t都视为候选动作。将每个候选动作分类为动作类别或背景，并进一步回归从当前时刻到动作开始和结束时刻的距离，从而获得精确的动作持续时间。上述过程可以描述为：
  $$
  V=\{v_{1},v_{2},...,v_{T}\}\rightarrow\hat{O}=\{\hat{o}_{1},\hat{o}_{2},...,\hat{o}_{T}\}.\hspace{2cm}(1)
  $$

* t时刻的输出定义为：$\hat{o}_{t}=(p(c_{t}),d_t^s,d_t^e)$，其中$p(c_{t})$表示t时刻每个动作类别的概率。$d_t^s>0,d_t^e>0$ 分别是当前时间与动作的开始时间和结束时间之间的偏移量。当t属于背景时，它们是无意义的。

* 时间动作定位结果可以通过下式获得：
  $$
  c_t=arg~max(p(c_t)),
  s_t=t-d_t^s,e_t=t+d_t^e.\hspace{3cm}(2)
  $$

### 体系结构概述

* TFFormer的pipeline如下图2所示：

  ![image-20241029154515567](C:\Users\PC\AppData\Roaming\Typora\typora-user-images\image-20241029154515567.png)

### 特征预处理

* 输入视频$V=\{v_1,v_2,...,v_T\}$被使用一个卷积投影网络 $\mathcal{G}(\cdot)$ 映射为一个D维的向量集合：
  $$
  x_t=\mathcal{G}(v_t)\in\mathcal{R}^{D\times1},X=\{x_1,x_2,...,x_T\}\in\mathcal{R}^{D \times T}.\hspace{3cm}(3)
  $$

* 然后将得到的特征向量馈送到编码器中。



## 多尺度时频特征编码器

**Multi-Scale Time-Frequency Feature Encoder**

